# ğŸ  Monitor de Coberturas - Lagoa, Rio de Janeiro

Monitora coberturas Ã  venda na Lagoa (RJ) via Zap ImÃ³veis.

## Arquitetura

```
GitHub Actions (diÃ¡rio 9:00 BRT)
  â†’ Playwright + Stealth scrapes Zap ImÃ³veis
  â†’ Salva dados/coberturas.json
  â†’ Envia push notification via Pushover
  â†’ Commit automÃ¡tico no repositÃ³rio

Streamlit Cloud
  â†’ LÃª dados/coberturas.json
  â†’ Exibe interface com filtros
  â†’ Permite disparar coleta manual
```

## Setup

### 1. Criar repositÃ³rio no GitHub
FaÃ§a upload de todos os arquivos para um repositÃ³rio no GitHub.

### 2. Configurar GitHub Secrets
No repositÃ³rio: **Settings â†’ Secrets and variables â†’ Actions**

Adicione:
- `PUSHOVER_API_TOKEN` â€” Token da sua aplicaÃ§Ã£o Pushover
- `PUSHOVER_USER_KEY` â€” Sua chave de usuÃ¡rio Pushover

### 3. Configurar Streamlit Cloud
1. Acesse [share.streamlit.io](https://share.streamlit.io)
2. Conecte seu repositÃ³rio
3. Aponte para `app.py`
4. Em **Settings â†’ Secrets**, adicione:
```toml
GITHUB_TOKEN = "ghp_seuTokenAqui"
GITHUB_REPO = "seuUsuario/seuRepo"
```

O `GITHUB_TOKEN` precisa ter permissÃ£o `actions:write` para que o botÃ£o
"Disparar Coleta" funcione. Crie em: GitHub â†’ Settings â†’ Developer settings â†’ Personal access tokens.

### 4. Primeira execuÃ§Ã£o
- VÃ¡ em **Actions** no GitHub e execute manualmente o workflow "Coleta de Coberturas"
- Ou aguarde a execuÃ§Ã£o automÃ¡tica Ã s 9:00h BRT

## Estrutura

```
â”œâ”€â”€ app.py                      # Interface Streamlit
â”œâ”€â”€ scraper.py                  # Scraper (roda no GitHub Actions)
â”œâ”€â”€ requirements.txt            # DependÃªncias do Streamlit Cloud
â”œâ”€â”€ dados/
â”‚   â”œâ”€â”€ coberturas.json         # Dados mais recentes
â”‚   â””â”€â”€ historico/              # HistÃ³rico diÃ¡rio
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ scrape.yml          # GitHub Actions workflow
â””â”€â”€ .streamlit/
    â””â”€â”€ secrets.toml.exemplo    # Template de secrets
```

## Notas

- **Cloudflare**: O Zap ImÃ³veis usa Cloudflare. O scraper usa `playwright-stealth`
  para tentar contornar, mas pode falhar. Os IPs do GitHub Actions sÃ£o diferentes
  dos residenciais e podem ter mais sucesso.
- **Se o scraping falhar**: O arquivo `coberturas.json` serÃ¡ salvo com lista vazia.
  Verifique os logs do GitHub Actions para diagnÃ³stico.
